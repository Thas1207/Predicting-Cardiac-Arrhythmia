# Predicting-Cardiac-Arrhythmia
Data Science project to detect patient's with risky and normal type of cardiac arrhythmia using machine learning algorithm

# Introduction
Heart diseases, including heart attack, heart failure, and arrhythmia, are the most prevalent cause of mortality worldwide. Among these heart diseases, cardiac arrhythmia is a type of ailment that results in sudden cardiac arrest due to changes in heart rhythm. In the United States alone, approximately 325,000 deaths of adults are attributed to cardiac arrhythmia every year (Beckerman, 2020). While some cases of cardiac arrhythmia are less severe, others can be hazardous and may result in serious complications such as stroke, heart failure, and sudden death. Risky arrhythmias may increase the possibility of blood clot formation, which, if dislodged, can travel to the brain and lead to a stroke (Heart arrhythmia - Symptoms and causes, 2022). Therefore, early detection of cardiac arrhythmia can reduce the risk of stroke and improve the success rate of treatments

# Objective
The aim of this paper is to construct machine learning algorithms capable of developing predictive models that can accurately distinguish between normal and high-risk types of arrhythmias. By doing so, healthcare providers can swiftly identify patients who require immediate treatment and provide timely medical attendtion accordingly, potentially reducing the risk of adverse outcomes.

# Business Understanding
By constructing predictive models for this categorization, the healthcare industry, including hospitals and pharmacists, can benefit greatly. For hospitals, having a model that can forecast the type of arrhythmia in patients will facilitate the selection of the most effective treatment and improve the accuracy of medical outcomes. Likewise, pharmacists can utilize this predictive model to design drugs that are tailored to each type of arrhythmia, ensuring that patients receive the appropriate medications for their particular condition. This will ultimately enhance customer satisfaction and optimize patient outcomes

# Methodology
**Data Acquisition**: The cardiac arrhythmia dataset was obtained from Kaggle at https://www.kaggle.com/code/batuhaneralpofficial/arrythmia-detection-from-ecg-data/data. The name of the dataset file is arrhythmia.csv and was downloaded at the same folder with the ipynb file. Jupyter notebook from Anaconda was used for python programming and SciKit Learn modules were used. The dataset consists of ECG waveform features, which determine the seriousness of the arrhythmia case. Other features that were included in the dataset were patientsâ€™ age, height, weight, and sex. There are 452 patients and 280 features in the dataset before pre-processing. Classes of arrhythmia in the dataset are determined and there is a total of 16 classes. These classes are the target variable for the dataset. Class 1 is normal, while 2-16 are risky classes

**Data Preprocessing**: Data cleaning is an essential step in any data analysis project, and it was performed on the dataset to ensure the accuracy and reliability of the analysis. The first step was to identify missing values in the dataset. Out of the total observations, 408 were found to be missing. To handle these missing values, the mean imputation method was used. This method involves replacing missing values with the mean value of that column.After handling missing values, the next step was to check for duplicate observations in the dataset. Fortunately, no duplicates were found, indicating that each observation in the dataset is unique. To gain a better understanding of the dataset, a summary of the dataset was generated, displaying the minimum, maximum, mean, and interquartile range of the data. Upon reviewing the summary, it was observed that the maximum value for the height attribute was 780cm, which seemed unlikely and incorrect. To correct this, the data for the height attribute was carefully examined, and it was discovered that the erroneous value was a typo and should have been 180cm. The missing value was corrected, ensuring that the dataset was accurate and reliable. Moreover, some attributes in the dataset had zero values for their statistical descriptions, indicating that these attributes were not significant in predicting the target variable. Therefore, these attributes were removed from the dataset, reducing the number of attributes and improving the efficiency of the analysis

**Exploratory Data Analysis (EDA)** : Exploratory Data Analysis (EDA) involved obtaining descriptive statistics by counting the number of occurrences for all categorical columns, including class, sex, and risky/normal type columns. The number of occurrences for each class was counted, and box plots were plotted to show the distribution of male and female with the classes of arrhythmia. Bar graphs were also drawn to show the distribution of each class. The mean value of age was calculated for each class for both females and males to determine the common age group diagnosed with arrhythmia. Additionally, scatter plots were plotted to clearly visualize the distribution of age for each class. Finally, feature selection was done to only choose the most suitable features for the predictive model by identifying p-values and using backward elimination to remove all features with p-values higher than 0.05

**Model Devlopment** : The dataset is split into two parts, namely, the train and test sets, before building the models. This is to assess the performance of the models on new data and to prevent overfitting of the models. The train set comprises 75% of the dataset, while the test set comprises 25%. Additionally, data scaling is performed on both the train and test sets to scale the values between 0 and 1. Supervised machine learning is used as the dataset is labelled with a target variable, and classification and regression methods are used to determine the best model for predicting patients with "Normal" or "Risky" arrhythmia. The models, Random Forest and Logistic Regression, are created and fitted into the train and test datasets, and their performance is evaluated using performance metrics such as accuracy, precision, recall, sensitivity, and specificity. The confusion matrix is also plotted to visualize the number of correct and incorrect predictions for each model. Finally, the Precision-Recall curve is plotted to evaluate the performance of the models in terms of correct predictions of positive and negative samples. A high area under the Precision-Recall curve indicates high precision (low false positive rates) and high recall (low false negative rates) for the models.

# Conclusion
In summary, two models were built to classify patients with normal arrhythmia and risky type arrhythmia. Random Forest achieved the best accuracy of 1.0 and can be used to predict patients at high risk who require immediate treatment. Logistic Regression model, on the other hand, gave an accuracy of 0.867 and misclassified some patients, which can be life-threatening. Random Forest model does not require any further improvement, but hyper-parameter tuning can be recommended for the Logistic Regression model to improve its accuracy. Overall, the solution provided in this study can help in the early detection of arrhythmia and improve patient outcomes by ensuring that they receive the appropriate treatment
